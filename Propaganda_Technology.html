<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>index.html</title>
  <style>
html {
color: #1a1a1a;
background-color: #fdfdfd;
}
body {
margin: 0 auto;
max-width: 36em;
padding-left: 50px;
padding-right: 50px;
padding-top: 50px;
padding-bottom: 50px;
hyphens: auto;
overflow-wrap: break-word;
text-rendering: optimizeLegibility;
font-kerning: normal;
}
@media (max-width: 600px) {
body {
font-size: 0.9em;
padding: 12px;
}
h1 {
font-size: 1.8em;
}
}
@media print {
html {
background-color: white;
}
body {
background-color: transparent;
color: black;
font-size: 12pt;
}
p, h2, h3 {
orphans: 3;
widows: 3;
}
h2, h3, h4 {
page-break-after: avoid;
}
}
p {
margin: 1em 0;
}
a {
color: #1a1a1a;
}
a:visited {
color: #1a1a1a;
}
img {
max-width: 100%;
}
svg {
height: auto;
max-width: 100%;
}
h1, h2, h3, h4, h5, h6 {
margin-top: 1.4em;
}
h5, h6 {
font-size: 1em;
font-style: italic;
}
h6 {
font-weight: normal;
}
ol, ul {
padding-left: 1.7em;
margin-top: 1em;
}
li > ol, li > ul {
margin-top: 0;
}
blockquote {
margin: 1em 0 1em 1.7em;
padding-left: 1em;
border-left: 2px solid #e6e6e6;
color: #606060;
}
code {
font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
font-size: 85%;
margin: 0;
hyphens: manual;
}
pre {
margin: 1em 0;
overflow: auto;
}
pre code {
padding: 0;
overflow: visible;
overflow-wrap: normal;
}
.sourceCode {
background-color: transparent;
overflow: visible;
}
hr {
background-color: #1a1a1a;
border: none;
height: 1px;
margin: 1em 0;
}
table {
margin: 1em 0;
border-collapse: collapse;
width: 100%;
overflow-x: auto;
display: block;
font-variant-numeric: lining-nums tabular-nums;
}
table caption {
margin-bottom: 0.75em;
}
tbody {
margin-top: 0.5em;
border-top: 1px solid #1a1a1a;
border-bottom: 1px solid #1a1a1a;
}
th {
border-top: 1px solid #1a1a1a;
padding: 0.25em 0.5em 0.25em 0.5em;
}
td {
padding: 0.125em 0.5em 0.25em 0.5em;
}
header {
margin-bottom: 4em;
text-align: center;
}
#TOC li {
list-style: none;
}
#TOC ul {
padding-left: 1.3em;
}
#TOC > ul {
padding-left: 0;
}
#TOC a:not(:hover) {
text-decoration: none;
}
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}

ul.task-list[class]{list-style: none;}
ul.task-list li input[type="checkbox"] {
font-size: inherit;
width: 0.8em;
margin: 0 0.8em 0.2em -1.6em;
vertical-align: middle;
}
</style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">History of Propaganda Technology</h1>
</header>
<h1 id="History">History</h1>
<p>
Information technology has repeatedly performed two functions throughout history. First it grants the very most powerful groups in a region the ability to control and spread information more broadly, more quickly, and with greater sophistication. Second, it gives some of the information proliferation ability that the elite posess to the individuals; It democratizes information. There have been some other unique and interesting effects and powers granted by particular technologies, but these have been the two major developments for information technologies in the past. Applying this course to the distribution of propaganda, we see a cycle where propaganda starts out highly democraticially distributed. Anyone can say anything to the people who will listen to them, in person face-to-face. If a person in power wishes to monopolize propaganda at this stage, they must do it via the consent of a network of people. They need soldiers to violently silence people and they need criers to repeat their message to the people. The spread of propaganda is optimally limited, and it takes maximal effort to monopolize propaganda when technology is minimized. With the advent of writing, anyone could create a document and it could spread to anyone. The people in power have the advantage of a network of people to copy and distribute the writings. To monopolize, they can: limit access to literacy knowledge, monopolize scribe positions by making private scribery illegal, and burn oppositional texts. Both the elite and the people have more access to getting their voices heard, but more so for the elite than the commons. Same pattern for the printing press (democratization of copying), the radio, the television, and eventually the internet. But each of these are somewhat unique and interesting. The television age may have been the single highest concentration of elite control over media in history. It certainly would have been if books didn't exist and weren't still often read. This is because there is a limited number of television broadcast channels available and they are entirely regulated by the government. Radio is the same way, but in the case of radio, there are frequencies reserved for ammature transmissions. The internet caused technology to become more democratic again. Domain Names and IP addresses are still regulated by a very few agencies, but there are far more of both of them, so it's less easy or necessary to regulate. Because access to dissemination of information has become universally accessible, they new currency is awareness. The modern technological/algorithmic developments and control are on the new front of awareness propogation rather than propagandistic information dissemination. So enters search engines and social media "algorithms". These are two technologies built with the express purpose of providing a person with information that they want to find without the user needing to know the exact location or source of the information. If a user wants to find dog shelters in a local area, without search engines, they would have limited options. They could go to a known forum for the local area and see if anyone had posted any links. Or they could go to some local meeting place like a library and see if anyone dropped any pamphlets. Critically, the website can only be found if the link has been posted in a way that could be found in a known public space. With search engines, they can search via key terms from a database that was built by automated web crawlers which scrape web pages for links. In effect, it's like checking every popular forum site, every link posted on every page linked to on all of those forum sites, etc. Because the database has so many links, the search engine engineers have the power to control what qualities push one result above another in the search term result order. These evaluations could be things like: alphabetical order, in-text relevance, metadata relevance, site popularity, and "which company pays us the most?". If only one group owned all of the search engines and other forms of awareness propogation (such as word-of-mouth or television) were to die off, and if people were to stop watching TV and reading books and listening to radio, then the search engine owner would have a true monopoly on propaganda without the need to publish a single article. All they have to do is control which information is accessible. This is the modern equivalent to the power to burn books, but it's highly automatable. Fortunately, it's not feasible to get a true monopoly on search engines because anyone could make their own web crawler. The engine results would be severely handicapped, but if someone is determined, they can get access to the information they want. But don't worry; there's a solution to this. In the same way that you don't have to burn books so long as you can get people to stop reading them, you don't need a monopoly on search engines so long as you can prevent people from searching. Social media algorithms are like search engines, but the search terms are all of the actions and behavior that a user exhibits on a given site. Things like subscriptions, previous searches, thumbnail clicks, watch time, comment engagement, etc. are all used in the "search query" to load the next recommended posts. Critically, during normal operation, the user does not expect to have direct control over what content he or she is presented with. So, within the realms of the social media platform, the platform has absolute and unquestionable control over user awareness. Individuals can directly spread awareness of their media via mechanisms outside of the platform (which is typically far less effective than in-platform spread).
</p>
<h1 id="Ethics of Social Media">Ethics of Social Media</h1>
<p>
Ethically, social media sites should act either as a platform or as a publisher. If they are a platform, then they have an ethical obligation to host all, even the most hateful of viewpoints and they must use only objective algorithms (such as "recent", "most upvotes", etc.), which the user should be able to switch between. If they are a publisher, then they are responsible and should be liable or all content on their site. Any post anywhere on the platform should be treated as an endorsement by the platform and they should act accordingly. Also, they have an ethical obligation to user privacy. Anything that a reasonable person would find invasive if people knew should be private by default. It should be truly private; the platform should not even collect or be able to collect the data. For example, Google Drive should store user files in an end-to-end encrypted manner. Drive has no reason to know the contents of your files. If they need it for some feature, it should be toggled on by the user and the user should be made to understand what they are giving up. To build trust and confidence that the platform is not collecting this information in secret, the frontend should be open-source and the API's should be publicly available so that anyone else can make their own frontend to the site. But the GREAT HACK shows important reasons why user privacy should be respected. In the GREAT HACK, Cambridge Analytica was shown to be using spear-phisching tactics to enhance the effectiveness of their propaganda. Spear-fisching is when a hacker uses information about a person to gain their trust in order to manipulate the person's actions or gain more information in order to gain security access to the organization. Typically, this is done by getting the victim to click on a link sent via email and fill out forms on a website. Consider how much more likely a victim is to follow these directions when they come from an email that is almost identical to his or her boss's email, going to a website that looks official, and emphasizing the urgency of the information needed by citing a real project that the victim is actually currently working on. By using information about which websites the company uses, the victim's management structure, and the victim's behavior, habbits, and current schedule allows the attacker to make a far more convincing piece of manipulative media. Cambridge Analytica was shown to be using these tactics, gathering much of the requisite data from Facebook. They may or may not have had priviledged access to the data, but certainly they scraped publically available Facebook information which Facebook encourages users to post and make publically available. I remember being 10 or 11 and wanting to make a Facebook account so I could play the Train Your Own Fish game. When signing up, they asked for a lot of personal information which even then I did not feel comfortable giving. I gave the accurate information because the forms implied that it was illegal for me to lie about my name, age, etc. To this day, I regret ever having done that.
</p>
<h1 id="Ethically Ideal Social Media Platform">Ethically Ideal Social Media Platform</h1>
<p>
The proper role of Social Media to be beneficial in society is as a properly democratized news network. Modern twitter supplies some good examples of this (although it does have many problems since it breaks the ethical code defined above). This is because it runs on the basic principle of an algorithm which pushes posts that people are most interested in, which is fantastic for the sake of democratized journalism. For example, it took about a week after video of Iryana Zarutska's death was released by the police to the local news networks before the major global news networks started talking about the story. They only published after they were forced to because it was the numbrer 1 topic on Twitter and people were starting to get angry that the major publications hadn't covered it. Multiple major publications condemned the people who posted the video on twitter as well, saying that it was disrespectful to Iryana and also that it was bad for her killer. As if he's someone we should be considering the feelings of. If it weren't for Twitter's Zipfian content presentation, Iryana's story would simply not have been told. By the way, many people on Twitter were claiming that the major media had been suppressing the story for nearly a month. From my personal research in the internet archives, the first New York Times coverage was only about a week after the video was available anywhere on the internet, first going to the local news network. It's just that the police did not release it for around 3 weeks, probably for reasons of investigative integrity. I would post sources, but I had to check the internet archive from day to day until I could find it; the sources would be enormous. Having said that, I think that the best format for this utility is in old fashioned forums, such as 4-chan. I know that 4-chan gets a bad reputation, but that's because you have to go out of your way to use 4-chan so only people who really don't want to be moderated go there, so it only has the kinds of posts that would be moderated on other platforms. If all platforms were unmoderated, then some of them would be mostly clean. 4-chan hosts many subject-topic-based forums. Once you find a basic subject, such as politics, then you can find topics. Such as "I think communism sucks because I hate the colour red" which will have a stream of comments under it. The topics are presented in order of most recent comment. This means that on any given subject, the topic you see first if you are not using the search bar is whatever most people are talking about at the time. This objective presentation metric removes 4-chan's ethical liability because they are not acting as a publisher in any way. The only moderation should be individuals being able to block other individuals so that their posts and comments do not appear in the discussion. This will obviously make every corner of the private journalism / public discussion section of the internet extremely unaccomodating to children, which is a good thing. More modern platforms for this which respect user privacy better include the modern FediVerse, including platforms like Mastodon, Gab, Lemmy, and p2ptube. These platforms allow users to simulaneously be publically accessible and also privately hosted. 
</p>
</body>
</html>
